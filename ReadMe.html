<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Visualization, Data Analysis, and Interaction Discussion</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>Visualization, Data Analysis, and Interaction Discussion</h1>

<h1>Clustering Methods</h1>

<ul>
<li>Lantent Semantic Analysis</li>
<li>Positive Pointwise Mutual Information</li>
<li>WordNet/MeSH</li>
</ul>

<h2>Custom</h2>

<ul>
<li>Get AverageArcLength</li>
<li>BeginRepeat</li>
<li>Take Smallest Arc</li>
<li>Place Point in middle of arc called NewCenter</li>
<li>Calculate Distance of all Points to the NewCenter and remove if Distance &lt; (Threshold * AverageArcLength) </li>
<li>If Arcs Removed &gt; Threshold2 GoTo BeginRepeat</li>
<li>Preform K-Means Clustering</li>
</ul>

<h2>Speedups</h2>

<h3>Best Bet</h3>

<ul>
<li><a href="http://www.indiana.edu/%7Eclcl/Papers/BSC901.pdf">http://www.indiana.edu/~clcl/Papers/BSC901.pdf</a></li>
</ul>

<h3>Ways to minimize the vocabulary.</h3>

<ul>
<li>Replace words that are highly specialized with a category, eg H2O-&gt;Chemical.</li>
<li>Remove words that are below some threshold in commonality.  (Word  * occurs in 1 out of 50,000 articles)</li>
<li>Remove words that are above some threshold. (Stop Words)</li>
<li>Use only pre-selected keywords eg. MeSH, or ones the client selects.</li>
</ul>

<h3>Encode in a Sparse Matrix.</h3>

<p>W is all words in all documents
V is set of all works in all documents
D is set of all documents</p>

<ul>
<li>For each Document, create a list of words and their count.

<ul>
<li>Dictionary<int,List<KeyValuePair<string,int>&gt; Documents;</li>
</ul></li>
<li>For each Word, create a list of Documents and their count.

<ul>
<li>Dictionary<string,Dictionary<int,int>&gt; Words</li>
</ul></li>
<li>Space for each Word would be

<ul>
<li>P(W|D) * N(D)</li>
</ul></li>
<li>Space for each Document would be

<ul>
<li>P(W|D) * N(W|D)</li>
</ul></li>
</ul>

<h4>Sparse vs Normal Matrix:</h4>

<p>Number of unique words in document * number of documents
\[ \sum_w^V{[P(w|\overline{D}) * N(D)]} + P(w \in D) * N(W|D) * N(D) vs N(W)*N(D) \]</p>

<h2>Improved Sparse Matrix</h2>

<pre><code>Dictionary&lt;int, Dictionary&lt;string,int&gt;&gt; Documents;
Dictionary&lt;int, Dictionary&lt;string,double&gt;&gt; PPMI;
Dictionary&lt;int, int&gt; DocumentWordCounts;
//Dictionary&lt;string, int&gt; WordCounts;
HashSet Vocabulary;
int WordCount;
int UniqueWordCount;
int DocumentCount;

UniqueWordCount = Vocabulary.Count;
DocumentCount = Documents.Count;
while(Documents.Count &gt; 0)
{
  KeyValuePair&lt;int,Dictionary&lt;string,int&gt;&gt; doc = Documents.First();
  while(doc.Value.Count &gt; 0)
  {
    Dictionary&lt;string,int&gt; dic = doc.Values.First();
    //foreach(string word in Vocabulary)
    foreach(string word in dic.Keys)
    {
      List&lt;int&gt; DocumentsContainingWord = Documents.Where(o=&gt;o.Value.ContainsKey(word)).Select(o=&gt;o.Key).AsList();
      int WordCount2 = 0;
      foreach(int doc2 in DocumentsContainingWord)
        WordCount2 += Documents[doc2][word];
      foreach(int doc2 in DocumentsContainingWord)
      {
        double P_of_w_given_d = ((double)(Documents[doc2][word] + DirichletSmoothAmmount) / (double)(UniqueWordCount*DirichletSmoothAmmount + DocumentWordCount[doc2]));
        double P_of_w = ((double)(/*WordCounts[word]*/ WordCount2 + DirichletSmoothAmmount)/(double)(WordCount+DirichletSmoothAmmount*UniqueWordCount*DocumentCount)) 
        int MI =  P_of_w_given_d/P_of_w;
        PMI = log2(MI);
        if(PMI &gt;= PostiveThreshold)
        {
          PPMI[doc2].Add(word, PMI)
          if(PPMI[doc2]==null)
            PPMI.add(doc2, new Dictionary&lt;string,int&gt;());
        }
        Documents[doc2].RemoveKey(word);
        if(Documents[doc2].Count == 0)
          Documents.RemoveKey(doc2)
        //PPMI = max(P(W|C)/P(W),PostiveThreshold)
      }
    }
  }
}
</code></pre>

<pre><code>Dictionary&lt;int, Dictionary&lt;string,int&gt;&gt; Documents;
Dictionary&lt;int, Dictionary&lt;string,double&gt;&gt; PPMI;
Dictionary&lt;int, int&gt; DocumentWordCounts;
//Dictionary&lt;string, int&gt; WordCounts;
HashSet Vocabulary;
int WordCount;
int UniqueWordCount;
int DocumentCount;

UniqueWordCount = Vocabulary.Count;
DocumentCount = Documents.Count;
foreach(string word in Vocabulary)
{
  List&lt;int&gt; DocumentsContainingWord = Documents.Where(o=&gt;o.Value.ContainsKey(word)).Select(o=&gt;o.Key).AsList();
  int WordCount2 = 0;
  foreach(int doc2 in DocumentsContainingWord)
    WordCount2 += Documents[doc2][word];
  foreach(int doc2 in DocumentsContainingWord)
  {
    double P_of_w_given_d = ((double)(Documents[doc2][word] + DirichletSmoothAmmount) / (double)(UniqueWordCount*DirichletSmoothAmmount + DocumentWordCount[doc2]));
        double P_of_w = ((double)(/*WordCounts[word]*/ WordCount2 + DirichletSmoothAmmount)/(double)(WordCount+DirichletSmoothAmmount*UniqueWordCount*DocumentCount)) 
    int MI =  P_of_w_given_d/P_of_w;
    PMI = log2(MI);
    if(PMI &gt;= PostiveThreshold)
    {
      if(PPMI[doc2]==null)
        PPMI.add(doc2, new Dictionary&lt;string,int&gt;());
      PPMI[doc2].Add(word, PMI)
    }
    //PPMI = max(P(W|C)/P(W),PostiveThreshold)
  }
}
</code></pre>

<p>Cosine Similarity</p>

<pre><code>CosineSimilarity(int doc1, int doc2)
{
  PPMI[doc1]
}
</code></pre>

<h3>Contact for the Fast PMI Network: : FLAG</h3>

<ul>
<li><a href="mailto:amit@umiacs.umd.edu">amit@umiacs.umd.edu</a></li>
</ul>

</body>

</html>

